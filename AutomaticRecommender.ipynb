{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Header import *\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'svg'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we present an automated recommender.\n",
    "The first part trains it and the second is the application for production."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_pickle(\"training_df.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_df(df, test_size = 0.2):\n",
    "    rand_idx = np.random.permutation(df.index)\n",
    "    test_size_idx = int(test_size*len(rand_idx))\n",
    "    train_idx, test_idx = rand_idx[test_size_idx:], rand_idx[:test_size_idx]\n",
    "    return df.iloc[train_idx], df.iloc[test_idx]\n",
    "\n",
    "df_train, df_test = split_df(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "from spacy.lang.en.stop_words import STOP_WORDS\n",
    "import spacy\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "def lemmatize(text):\n",
    "    with nlp.disable_pipes(\"tagger\", \"parser\"):\n",
    "        document = nlp(text)\n",
    "        lemma = [w.lemma_.lower() for w in document]\n",
    "        return lemma\n",
    "\n",
    "def removeStopWords(lemmas):\n",
    "    filtered_sentence =[] \n",
    "    for word in lemmas:\n",
    "        if not word in STOP_WORDS:\n",
    "            filtered_sentence.append(word) \n",
    "    return \" \".join(filtered_sentence)\n",
    "    \n",
    "def prepare_vector(sentences, labels):\n",
    "    # X\n",
    "    lemmas = map(lemmatize, sentences)\n",
    "    noStop = map(removeStopWords, lemmas)\n",
    "    vectorizer = CountVectorizer(binary=True, strip_accents='unicode', lowercase=True,\n",
    "                             stop_words=None, token_pattern='[a-z]{3,}', max_df=0.3)\n",
    "    # tokens only with 3 or more characters and no numbers\n",
    "    X = vectorizer.fit_transform(noStop).toarray()\n",
    "    vectorizer.fixed_vocabulary_=True\n",
    "    \n",
    "    # y\n",
    "    encoder = LabelEncoder()\n",
    "    y = encoder.fit_transform(labels)\n",
    "    \n",
    "    return X, y, vectorizer, encoder\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=0.3, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "          n_jobs=None, penalty='l2', random_state=None, solver='liblinear',\n",
       "          tol=0.0001, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import linear_model\n",
    "from sklearn.feature_selection import RFECV\n",
    "\n",
    "X, y, vectorizer, encoder = prepare_vector(df_train.Sentence, df_train.PositiveLabel)\n",
    "maxent = linear_model.LogisticRegression(penalty='l2', C=0.3, solver='liblinear')\n",
    "maxent.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Application"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rank_positive(sentences, vectorizer, encoder, maxent):\n",
    "    # Prepare X\n",
    "    sentences=df_test.Sentence\n",
    "    lemmas = map(lemmatize, sentences)\n",
    "    noStop = map(removeStopWords, lemmas)\n",
    "    X = vectorizer.transform(noStop).toarray()\n",
    "\n",
    "    # Sort by probability p and exclude p<=0.5\n",
    "    positive_proba = maxent.predict_proba(X)[:, np.where(encoder.classes_=='Positive')[0][0]]\n",
    "    sort_idx = np.argsort(positive_proba)[::-1]\n",
    "    sorted_proba = positive_proba[sort_idx]\n",
    "    sort_idx_cut = sort_idx[sorted_proba > 0.5]\n",
    "    X = X[sort_idx_cut]\n",
    "\n",
    "    # List 3 most important words\n",
    "    eps=0.1\n",
    "    important_words_idx = (np.abs(maxent.coef_[0,:]*X)>eps)\n",
    "    pos_words_coeff = []; neg_words_coeff = []\n",
    "    for iw in important_words_idx:\n",
    "        word_list = vectorizer.inverse_transform(iw)[0]\n",
    "        coeff_list = maxent.coef_[0,iw]\n",
    "        # Sort by coefficient\n",
    "        sort_idx = np.argsort(coeff_list)[::-1]\n",
    "        # Collect positive words\n",
    "        pos_words_coeff.append([])\n",
    "        for i, (wl, wc) in enumerate(zip(word_list[sort_idx], coeff_list[sort_idx])):\n",
    "            if i>=3:\n",
    "                break\n",
    "            if wc>0:\n",
    "                pos_words_coeff[-1].append([ wl, wc ])\n",
    "        # Collect negative words\n",
    "        neg_words_coeff.append([])\n",
    "        for i, (wl, wc) in enumerate(zip(word_list[sort_idx][::-1], coeff_list[sort_idx][::-1])):\n",
    "            if i>=3:\n",
    "                break\n",
    "            if wc<0:\n",
    "                neg_words_coeff[-1].append([ wl, wc ])\n",
    "    return pd.DataFrame({'Sentence' : sentences.values[sort_idx_cut],\n",
    "                       'PositiveProba' : positive_proba[sort_idx_cut],\n",
    "                       'PositiveWords' : pos_words_coeff,\n",
    "                       'NegativeWords' : neg_words_coeff\n",
    "                      })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probability to be positive: 0.896\n",
      "Positive words and score: clinical (0.37), analysis (0.30), sma (0.30)\n",
      "Negative words and score: randomize (-0.22), efficacy (-0.15), label (-0.14)\n",
      "This was supported by favourable safety and efficacy data from the interim analysis of a randomized controlled clinical study, CS4 in later-onset subjects, open-label studies in pre-symptomatic subjects, and subjects with infantile-onset and later-onset SMA, where the attainment of motor milestones in subjects receiving treatment differed from that seen in the natural history of SMA\n",
      "\n",
      "Probability to be positive: 0.883\n",
      "Positive words and score: consider (0.38), bioequivalence (0.38), clinical (0.37)\n",
      "Negative words and score: medicinal (-0.27), chmp (-0.23)\n",
      "Therefore the absence of a bioequivalence study was considered justified and the CHMP concluded that no clinical data were needed to support the application for Lacosamide Accord 50 mg, 100 mg, 150 mg and 200 mg film-coated tablets as a generic medicinal product to Vimpat.\n",
      "\n",
      "Probability to be positive: 0.880\n",
      "Positive words and score: sma (0.30), nusinersen (0.25), strength (0.21)\n",
      "Negative words and score: \n",
      "Data from treated pre-symptomatic infants with genetically confirmed SMA show that they are achieving motor milestones and developing muscle strength and motor function with the nusinersen treatment that are more consistent with those of normal infants than symptomatic infants with SMA\n",
      "\n",
      "Probability to be positive: 0.840\n",
      "Positive words and score: profile (0.47), consider (0.38), concern (0.34)\n",
      "Negative words and score: safety (-0.12)\n",
      "Overall, the safety profile of PPS is not considered of concern.\n",
      "\n",
      "Probability to be positive: 0.818\n",
      "Positive words and score: week (0.34), support (0.23), observe (0.20)\n",
      "Negative words and score: non (-0.20), svr (-0.17), population (-0.11)\n",
      "In the HCV GT1-infected population (the most widely represented in the EU) the observed results -with 99% SVR12 achieved with a convenient 8 weeks treatment duration in non-cirrhotic TN or TE-PRS patients and 97% in cirrhotic patients with a 12 weeks treatment duration- support the fact that this FDC will represent an optimization in the therapeutic armamentarium. \n",
      "\n"
     ]
    }
   ],
   "source": [
    "rp = rank_positive(df_test.Sentence, vectorizer, encoder, maxent)\n",
    "\n",
    "for i in range(5):\n",
    "    print(\"Probability to be positive: {:.3f}\".format(rp.PositiveProba.iloc[i]))\n",
    "    print(\"Positive words and score: \"+\", \"\n",
    "          .join([\"{} ({:.2f})\".format(w, s) for w, s in rp.PositiveWords.iloc[i]]))\n",
    "    print(\"Negative words and score: \"+\", \"\n",
    "          .join([\"{} ({:.2f})\".format(w, s) for w, s in rp.NegativeWords.iloc[i]]))\n",
    "    print(rp.Sentence.iloc[i])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Application and check that it works"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rank_positive_check(sentences, vectorizer, encoder, maxent, y):\n",
    "    # Prepare X\n",
    "    sentences=df_test.Sentence\n",
    "    lemmas = map(lemmatize, sentences)\n",
    "    noStop = map(removeStopWords, lemmas)\n",
    "    X = vectorizer.transform(noStop).toarray()\n",
    "\n",
    "    # Sort by probability p and exclude p<=0.5\n",
    "    positive_proba = maxent.predict_proba(X)[:, np.where(encoder.classes_=='Positive')[0][0]]\n",
    "    sort_idx = np.argsort(positive_proba)[::-1]\n",
    "    sorted_proba = positive_proba[sort_idx]\n",
    "    sort_idx_cut = sort_idx[sorted_proba > 0.5]\n",
    "    X = X[sort_idx_cut]\n",
    "\n",
    "    # List 3 most important words\n",
    "    eps=0.1\n",
    "    important_words_idx = (np.abs(maxent.coef_[0,:]*X)>eps)\n",
    "    pos_words_coeff = []; neg_words_coeff = []\n",
    "    for iw in important_words_idx:\n",
    "        word_list = vectorizer.inverse_transform(iw)[0]\n",
    "        coeff_list = maxent.coef_[0,iw]\n",
    "        # Sort by coefficient\n",
    "        sort_idx = np.argsort(coeff_list)[::-1]\n",
    "        # Collect positive words\n",
    "        pos_words_coeff.append([])\n",
    "        for i, (wl, wc) in enumerate(zip(word_list[sort_idx], coeff_list[sort_idx])):\n",
    "            if i>=3:\n",
    "                break\n",
    "            if wc>0:\n",
    "                pos_words_coeff[-1].append([ wl, wc ])\n",
    "        # Collect negative words\n",
    "        neg_words_coeff.append([])\n",
    "        for i, (wl, wc) in enumerate(zip(word_list[sort_idx][::-1], coeff_list[sort_idx][::-1])):\n",
    "            if i>=3:\n",
    "                break\n",
    "            if wc<0:\n",
    "                neg_words_coeff[-1].append([ wl, wc ])\n",
    "                \n",
    "    return pd.DataFrame({'Sentence' : sentences.values[sort_idx_cut],\n",
    "                       'PositiveProba' : positive_proba[sort_idx_cut],\n",
    "                       'PositiveWords' : pos_words_coeff,\n",
    "                       'NegativeWords' : neg_words_coeff,\n",
    "                       'CorrectLabel' : y.values[sort_idx_cut]\n",
    "                      })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probability to be positive: 0.896 and correct label: Positive\n",
      "Positive words and score: clinical (0.37), analysis (0.30), sma (0.30)\n",
      "Negative words and score: randomize (-0.22), efficacy (-0.15), label (-0.14)\n",
      "This was supported by favourable safety and efficacy data from the interim analysis of a randomized controlled clinical study, CS4 in later-onset subjects, open-label studies in pre-symptomatic subjects, and subjects with infantile-onset and later-onset SMA, where the attainment of motor milestones in subjects receiving treatment differed from that seen in the natural history of SMA\n",
      "\n",
      "Probability to be positive: 0.883 and correct label: Positive\n",
      "Positive words and score: consider (0.38), bioequivalence (0.38), clinical (0.37)\n",
      "Negative words and score: medicinal (-0.27), chmp (-0.23)\n",
      "Therefore the absence of a bioequivalence study was considered justified and the CHMP concluded that no clinical data were needed to support the application for Lacosamide Accord 50 mg, 100 mg, 150 mg and 200 mg film-coated tablets as a generic medicinal product to Vimpat.\n",
      "\n",
      "Probability to be positive: 0.880 and correct label: Positive\n",
      "Positive words and score: sma (0.30), nusinersen (0.25), strength (0.21)\n",
      "Negative words and score: \n",
      "Data from treated pre-symptomatic infants with genetically confirmed SMA show that they are achieving motor milestones and developing muscle strength and motor function with the nusinersen treatment that are more consistent with those of normal infants than symptomatic infants with SMA\n",
      "\n",
      "Probability to be positive: 0.840 and correct label: Positive\n",
      "Positive words and score: profile (0.47), consider (0.38), concern (0.34)\n",
      "Negative words and score: safety (-0.12)\n",
      "Overall, the safety profile of PPS is not considered of concern.\n",
      "\n",
      "Probability to be positive: 0.818 and correct label: Positive\n",
      "Positive words and score: week (0.34), support (0.23), observe (0.20)\n",
      "Negative words and score: non (-0.20), svr (-0.17), population (-0.11)\n",
      "In the HCV GT1-infected population (the most widely represented in the EU) the observed results -with 99% SVR12 achieved with a convenient 8 weeks treatment duration in non-cirrhotic TN or TE-PRS patients and 97% in cirrhotic patients with a 12 weeks treatment duration- support the fact that this FDC will represent an optimization in the therapeutic armamentarium. \n",
      "\n",
      "Probability to be positive: 0.800 and correct label: Positive\n",
      "Positive words and score: support (0.23), available (0.22), avelumab (0.17)\n",
      "Negative words and score: efficacy (-0.15), naive (-0.11)\n",
      "Taking into account the intrinsic limitation of single arm studies, the rarity of the disease and the challenges to compare the results with data from historical controls and in the literature, the currently available data are deemed to support the efficacy of avelumab in both pre-treated and chemotherapy-naÃ¯ve patients\n",
      "\n",
      "Probability to be positive: 0.778 and correct label: Positive\n",
      "Positive words and score: consider (0.38), overall (0.32), indication (0.19)\n",
      "Negative words and score: submit (-0.31), population (-0.11)\n",
      "Overall, data of the submitted studies are considered overall adequate to identify the patient population of the indication.\n",
      "\n",
      "Probability to be positive: 0.777 and correct label: Neutral\n",
      "Positive words and score: profile (0.47), sma (0.30), subject (0.26)\n",
      "Negative words and score: randomize (-0.22), label (-0.14), open (-0.14)\n",
      "The safety profile of nusinersen was characterized in subjects with infantile-onset SMA in a randomized controlled study and an open-label study; pre-symptomatic infants with SMA in an open-label study, and children with later-onset SMA in a randomized study and open-label studies\n",
      "\n",
      "Probability to be positive: 0.764 and correct label: Positive\n",
      "Positive words and score: rate (0.31), reduction (0.30), observe (0.20)\n",
      "Negative words and score: difference (-0.52)\n",
      "Also, the observed 23% reduction in the exacerbation rate is above the minimum clinically important difference.\n",
      "\n",
      "Probability to be positive: 0.755 and correct label: Neutral\n",
      "Positive words and score: nusinersen (0.25), compare (0.16), maintain (0.16)\n",
      "Negative words and score: event (-0.10)\n",
      "Pre-symptomatic infants treated with nusinersen experienced fewer adverse events compared with symptomatic infants which is most likely due to their healthier baseline condition, which they maintained throughout participation in the study\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rp = rank_positive_check(df_test.Sentence, vectorizer, encoder, maxent, df_test.Label)\n",
    "\n",
    "for i in range(10):\n",
    "    print(\"Probability to be positive: {:.3f} and correct label: {}\"\n",
    "          .format(rp.PositiveProba.iloc[i], rp.CorrectLabel.iloc[i]))\n",
    "    print(\"Positive words and score: \"+\", \"\n",
    "          .join([\"{} ({:.2f})\".format(w, s) for w, s in rp.PositiveWords.iloc[i]]))\n",
    "    print(\"Negative words and score: \"+\", \"\n",
    "          .join([\"{} ({:.2f})\".format(w, s) for w, s in rp.NegativeWords.iloc[i]]))\n",
    "    print(rp.Sentence.iloc[i])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
